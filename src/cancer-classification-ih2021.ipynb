{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install timm -q\n!pip install albumentations --upgrade -q\n!pip install segmentation_models_pytorch -q\n\n# General imports.\nimport gc\nimport os\nimport cv2\nimport timm\nimport torch\nimport random\nimport sklearn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport albumentations as A\nimport segmentation_models_pytorch\n\n\n# Specific Imports.\nfrom torch import nn\nfrom tqdm import tqdm\nfrom tensorflow import keras\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom kaggle_datasets import KaggleDatasets\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom segmentation_models_pytorch.encoders import get_encoder\nfrom timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\nfrom segmentation_models_pytorch.base import initialization as init\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-22T08:05:03.834099Z","iopub.execute_input":"2021-08-22T08:05:03.834600Z","iopub.status.idle":"2021-08-22T08:05:45.669736Z","shell.execute_reply.started":"2021-08-22T08:05:03.834495Z","shell.execute_reply":"2021-08-22T08:05:45.668472Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install wandb -qqq\n# import wandb\n# from wandb.keras import WandbCallback\n# wandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:51.384221Z","iopub.execute_input":"2021-08-22T05:24:51.384639Z","iopub.status.idle":"2021-08-22T05:24:51.388838Z","shell.execute_reply.started":"2021-08-22T05:24:51.384592Z","shell.execute_reply":"2021-08-22T05:24:51.387607Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions","metadata":{}},{"cell_type":"code","source":"def seed_everything(SEED):\n    os.environ['PYTHONHASHSEED']=str(SEED)\n    random.seed(SEED)\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    \ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:07:06.313820Z","iopub.execute_input":"2021-08-22T08:07:06.314310Z","iopub.status.idle":"2021-08-22T08:07:06.322941Z","shell.execute_reply.started":"2021-08-22T08:07:06.314276Z","shell.execute_reply":"2021-08-22T08:07:06.321565Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Brief Descriptive Analysis and EDA (EDA can be done later)","metadata":{}},{"cell_type":"code","source":"# Ref: https://www.kaggle.com/andrewmvd/isic-2019.\n# Note: Everything is done within a Kaggle Notebook. Minor edits will be made transitioning to github.\n\ntrain_val_test_img_path = r\"/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\ngt_path = r\"/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv\"\nmetadata_path = r\"/kaggle/input/isic-2019/ISIC_2019_Training_Metadata.csv\"\n\nground_truth_df = pd.read_csv(gt_path)\nmetadata_df = pd.read_csv(metadata_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T08:07:07.868620Z","iopub.execute_input":"2021-08-22T08:07:07.869019Z","iopub.status.idle":"2021-08-22T08:07:08.019560Z","shell.execute_reply.started":"2021-08-22T08:07:07.868990Z","shell.execute_reply":"2021-08-22T08:07:08.018295Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(\"Ground Truth DataFrame\"); display(ground_truth_df)\nprint(\"\")\nprint(\"Metadata DataFrame\"); display(metadata_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:51.595306Z","iopub.execute_input":"2021-08-22T05:24:51.595916Z","iopub.status.idle":"2021-08-22T05:24:51.666013Z","shell.execute_reply.started":"2021-08-22T05:24:51.595874Z","shell.execute_reply":"2021-08-22T05:24:51.664805Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Ground Truth DataFrame\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n0      ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n1      ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2      ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n3      ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n4      ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n...             ...  ...  ...  ...  ...  ...  ...   ...  ...  ...\n25326  ISIC_0073247  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n25327  ISIC_0073248  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n25328  ISIC_0073249  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n25329  ISIC_0073251  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n25330  ISIC_0073254  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n\n[25331 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>MEL</th>\n      <th>NV</th>\n      <th>BCC</th>\n      <th>AK</th>\n      <th>BKL</th>\n      <th>DF</th>\n      <th>VASC</th>\n      <th>SCC</th>\n      <th>UNK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000001</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000002</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000003</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000004</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25326</th>\n      <td>ISIC_0073247</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25327</th>\n      <td>ISIC_0073248</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25328</th>\n      <td>ISIC_0073249</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25329</th>\n      <td>ISIC_0073251</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25330</th>\n      <td>ISIC_0073254</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>25331 rows × 10 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nMetadata DataFrame\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              image  age_approx anatom_site_general    lesion_id     sex\n0      ISIC_0000000        55.0      anterior torso          NaN  female\n1      ISIC_0000001        30.0      anterior torso          NaN  female\n2      ISIC_0000002        60.0     upper extremity          NaN  female\n3      ISIC_0000003        30.0     upper extremity          NaN    male\n4      ISIC_0000004        80.0     posterior torso          NaN    male\n...             ...         ...                 ...          ...     ...\n25326  ISIC_0073247        85.0           head/neck  BCN_0003925  female\n25327  ISIC_0073248        65.0      anterior torso  BCN_0001819    male\n25328  ISIC_0073249        70.0     lower extremity  BCN_0001085    male\n25329  ISIC_0073251        55.0         palms/soles  BCN_0002083  female\n25330  ISIC_0073254        50.0     upper extremity  BCN_0001079    male\n\n[25331 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>age_approx</th>\n      <th>anatom_site_general</th>\n      <th>lesion_id</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0000000</td>\n      <td>55.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0000001</td>\n      <td>30.0</td>\n      <td>anterior torso</td>\n      <td>NaN</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0000002</td>\n      <td>60.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0000003</td>\n      <td>30.0</td>\n      <td>upper extremity</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0000004</td>\n      <td>80.0</td>\n      <td>posterior torso</td>\n      <td>NaN</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25326</th>\n      <td>ISIC_0073247</td>\n      <td>85.0</td>\n      <td>head/neck</td>\n      <td>BCN_0003925</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>25327</th>\n      <td>ISIC_0073248</td>\n      <td>65.0</td>\n      <td>anterior torso</td>\n      <td>BCN_0001819</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>25328</th>\n      <td>ISIC_0073249</td>\n      <td>70.0</td>\n      <td>lower extremity</td>\n      <td>BCN_0001085</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>25329</th>\n      <td>ISIC_0073251</td>\n      <td>55.0</td>\n      <td>palms/soles</td>\n      <td>BCN_0002083</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>25330</th>\n      <td>ISIC_0073254</td>\n      <td>50.0</td>\n      <td>upper extremity</td>\n      <td>BCN_0001079</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n<p>25331 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Exploring the Ground Truth DataFrame.\nprint(f\"Shape of Dataset: {ground_truth_df.shape}\")\nprint(f\"Number of Unique Image Identifiers (ID): {ground_truth_df.image.nunique()}\", end=\"\\n\\n\")\nprint(\"<=======Info=======>\")\nground_truth_df.info(); print()\n\n## Checking the validity of all unique values in the \"image\" column.\nfor idx, image_name in enumerate(ground_truth_df[\"image\"]):\n    if \"ISIC_\" not in image_name: print(f\"Row {idx} has an invalid image name.\")\n\n## Looking at both the unique values for each column and their counts.\nprint(\"<=======Value Counts=======>\")\nfor column in ground_truth_df.columns:\n    display(ground_truth_df[column].value_counts().sort_index()); print()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:51.667708Z","iopub.execute_input":"2021-08-22T05:24:51.668065Z","iopub.status.idle":"2021-08-22T05:24:51.856283Z","shell.execute_reply.started":"2021-08-22T05:24:51.668028Z","shell.execute_reply":"2021-08-22T05:24:51.854983Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Shape of Dataset: (25331, 10)\nNumber of Unique Image Identifiers (ID): 25331\n\n<=======Info=======>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25331 entries, 0 to 25330\nData columns (total 10 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   image   25331 non-null  object \n 1   MEL     25331 non-null  float64\n 2   NV      25331 non-null  float64\n 3   BCC     25331 non-null  float64\n 4   AK      25331 non-null  float64\n 5   BKL     25331 non-null  float64\n 6   DF      25331 non-null  float64\n 7   VASC    25331 non-null  float64\n 8   SCC     25331 non-null  float64\n 9   UNK     25331 non-null  float64\ndtypes: float64(9), object(1)\nmemory usage: 1.9+ MB\n\n<=======Value Counts=======>\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ISIC_0000000    1\nISIC_0000001    1\nISIC_0000002    1\nISIC_0000003    1\nISIC_0000004    1\n               ..\nISIC_0073247    1\nISIC_0073248    1\nISIC_0073249    1\nISIC_0073251    1\nISIC_0073254    1\nName: image, Length: 25331, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    20809\n1.0     4522\nName: MEL, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    12456\n1.0    12875\nName: NV, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    22008\n1.0     3323\nName: BCC, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    24464\n1.0      867\nName: AK, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    22707\n1.0     2624\nName: BKL, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    25092\n1.0      239\nName: DF, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    25078\n1.0      253\nName: VASC, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    24703\n1.0      628\nName: SCC, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0    25331\nName: UNK, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Exploring the Metadata DataFrame.\nprint(f\"Shape of Dataset: {metadata_df.shape}\")\nprint(f\"Number of Unique Image Identifiers (ID): {metadata_df.image.nunique()}\", end=\"\\n\\n\")\nprint(\"<=======Info=======>\")\nmetadata_df.info(); print()\n\n## Checking the validity of all unique values in the \"image\" column.\nfor idx, image_name in enumerate(metadata_df[\"image\"]):\n    if \"ISIC_\" not in image_name: print(f\"Row {idx} has an invalid image name.\")\n\n## Looking at both the unique values for each column and their counts.\nprint(\"<=======Value Counts=======>\")\nfor column in metadata_df.columns:\n    display(metadata_df[column].value_counts().sort_index()); print()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:51.858106Z","iopub.execute_input":"2021-08-22T05:24:51.858580Z","iopub.status.idle":"2021-08-22T05:24:52.055311Z","shell.execute_reply.started":"2021-08-22T05:24:51.858529Z","shell.execute_reply":"2021-08-22T05:24:52.054287Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Shape of Dataset: (25331, 5)\nNumber of Unique Image Identifiers (ID): 25331\n\n<=======Info=======>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25331 entries, 0 to 25330\nData columns (total 5 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   image                25331 non-null  object \n 1   age_approx           24894 non-null  float64\n 2   anatom_site_general  22700 non-null  object \n 3   lesion_id            23247 non-null  object \n 4   sex                  24947 non-null  object \ndtypes: float64(1), object(4)\nmemory usage: 989.6+ KB\n\n<=======Value Counts=======>\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ISIC_0000000    1\nISIC_0000001    1\nISIC_0000002    1\nISIC_0000003    1\nISIC_0000004    1\n               ..\nISIC_0073247    1\nISIC_0073248    1\nISIC_0073249    1\nISIC_0073251    1\nISIC_0073254    1\nName: image, Length: 25331, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0.0       54\n5.0      113\n10.0     142\n15.0     375\n20.0     388\n25.0     677\n30.0    1199\n35.0    1651\n40.0    2246\n45.0    2585\n50.0    2489\n55.0    2170\n60.0    2036\n65.0    2075\n70.0    2120\n75.0    1796\n80.0    1459\n85.0    1319\nName: age_approx, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"anterior torso     6915\nhead/neck          4587\nlateral torso        54\nlower extremity    4990\noral/genital         59\npalms/soles         398\nposterior torso    2787\nupper extremity    2910\nName: anatom_site_general, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"BCN_0000001     3\nBCN_0000002     3\nBCN_0000003     2\nBCN_0000004     6\nBCN_0000008     3\n               ..\nMSK4_0012050    1\nMSK4_0012052    1\nMSK4_0012054    1\nMSK4_0012056    1\nMSK4_0012066    1\nName: lesion_id, Length: 11847, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"female    11661\nmale      13286\nName: sex, dtype: int64"},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Exploring the images folder.\nfiles = os.listdir(train_val_test_img_path)\nprint(f\"Number of files in train folder: {len(files)}\")\nfor file in files:\n    if \".jpg\" not in file:\n        print(f\"Non-Image File Found: {file}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:52.057883Z","iopub.execute_input":"2021-08-22T05:24:52.058282Z","iopub.status.idle":"2021-08-22T05:24:53.209355Z","shell.execute_reply.started":"2021-08-22T05:24:52.058239Z","shell.execute_reply":"2021-08-22T05:24:53.207954Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of files in train folder: 25333\nNon-Image File Found: LICENSE.txt\nNon-Image File Found: ATTRIBUTION.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameters and Pre-defined Terms","metadata":{}},{"cell_type":"code","source":"classes = [\n    'Melanoma',\n    'Melanocytic nevus',\n    'Basal cell carcinoma',\n    'Actinic keratosis',\n    'Benign keratosis', # Also: (solar lentigo / seborrheic keratosis / lichen planus-like keratosis).\n    'Dermatofibroma',\n    'Vascular lesion',\n    'Squamous cell carcinoma',\n    'Unknown' # Used for unlabelled scans.\n]\n\nclasses_abbrev = [\"MEL\",\"NV\",\"BCC\",\"AK\",\"BKL\",\"DF\",\"VASC\",\"SCC\",\"UNK\"]\n\n# Final classes dictionary which excludes \"Unknown\" classes.\nCLASSES_DICT = dict(tuple(zip(classes_abbrev[:-1], classes[:-1])))\n\nseed = 42\nn_splits = 1\nbatch_size = strategy.num_replicas_in_sync * 20\n\nencoder_name = \"timm-efficientnet-b5\"\nin_channels = 3\ndepth = 5\npretrained_weights = \"noisy-student\"\nin_features = 1024\nstrategy = auto_select_accelerator()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninit_lr = 0.0001\n\nepochs = 20\n\nMODEL_SAVE_PATH = '{}.pth'.format(encoder_name)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:40:27.995369Z","iopub.execute_input":"2021-08-22T05:40:27.996058Z","iopub.status.idle":"2021-08-22T05:40:33.762485Z","shell.execute_reply.started":"2021-08-22T05:40:27.996001Z","shell.execute_reply":"2021-08-22T05:40:33.761331Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Running on TPU: grpc://10.0.0.2:8470\nRunning on 8 replicas\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset Generator","metadata":{}},{"cell_type":"code","source":"class skin_cancer_ds(Dataset):\n    def __init__(self, df, image_size, mode):\n        super(skin_cancer_ds, self).__init__()\n        self.df = df\n        self.image_size = image_size\n        assert mode in ['train', 'valid', 'test']\n        self.mode = mode\n\n        if self.mode == 'train':\n            self.transform = A.Compose([\n                A.RandomResizedCrop(height=self.image_size, width=self.image_size, scale=(0.25, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1, p=1.0),\n                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=30, interpolation=1, border_mode=0, value=0, p=0.25),\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.OneOf([\n                    A.MotionBlur(p=.2),\n                    A.MedianBlur(blur_limit=3, p=0.1),\n                    A.Blur(blur_limit=3, p=0.1),\n                ], p=0.25),\n                A.Cutout(num_holes=4, max_h_size=32, max_w_size=32, fill_value=0, p=0.25),\n                A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n                ToTensorV2(),\n            ])\n\n        else:\n            self.transform = A.Compose([\n                A.Resize(self.image_size, self.image_size),\n                A.Normalize(mean=IMAGENET_DEFAULT_MEAN, std=IMAGENET_DEFAULT_STD),\n                ToTensorV2(),\n            ])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        img_path = train_val_test_img_path + f'/{self.df.loc[index][\"image\"]}.jpg'\n        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        image = np.stack([image, image, image], axis=-1)\n        image = self.transform(image=image)[\"image\"]\n        if self.mode in ['train', 'valid']:\n            label = torch.tensor(np.argmax(self.df.loc[index, CLASSES_DICT].values))\n            # label = torch.Tensor(self.df.loc[index, CLASSES_DICT])\n            return image, label\n        else:\n            return image","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.224674Z","iopub.execute_input":"2021-08-22T05:24:53.225206Z","iopub.status.idle":"2021-08-22T05:24:53.243666Z","shell.execute_reply.started":"2021-08-22T05:24:53.225143Z","shell.execute_reply":"2021-08-22T05:24:53.242472Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"seed_everything(seed)\n\n# Splitting train and val from test via a stratified shuffle split.\ntrainval_test_split = StratifiedShuffleSplit(n_splits=n_splits, train_size=0.9, random_state=seed)\nfor train_val_index, test_index in trainval_test_split.split(ground_truth_df[\"image\"].values, \n                                                             np.argmax(ground_truth_df[CLASSES_DICT].values, axis=1)\n):\n    train_val_df = ground_truth_df.loc[train_val_index].reset_index(drop=True)\n    test_df = ground_truth_df.loc[test_index].reset_index(drop=True)\n\n# Splitting train and val via a stratified shuffle split.\ntrain_val_split = StratifiedShuffleSplit(n_splits=n_splits, train_size=0.9, random_state=seed)\nfor train_index, val_index in train_val_split.split(train_val_df[\"image\"].values, \n                                                    np.argmax(train_val_df[CLASSES_DICT].values, axis=1)\n):\n    train_df = train_val_df.loc[train_index].reset_index(drop=True)\n    val_df = train_val_df.loc[val_index].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.245312Z","iopub.execute_input":"2021-08-22T05:24:53.245710Z","iopub.status.idle":"2021-08-22T05:24:53.322970Z","shell.execute_reply.started":"2021-08-22T05:24:53.245668Z","shell.execute_reply":"2021-08-22T05:24:53.321891Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.324472Z","iopub.execute_input":"2021-08-22T05:24:53.324774Z","iopub.status.idle":"2021-08-22T05:24:53.356661Z","shell.execute_reply.started":"2021-08-22T05:24:53.324744Z","shell.execute_reply":"2021-08-22T05:24:53.355353Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n0                  ISIC_0027389  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n1                  ISIC_0073068  0.0  0.0  0.0  1.0  0.0  0.0   0.0  0.0  0.0\n2                  ISIC_0059070  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n3                  ISIC_0072522  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n4                  ISIC_0030159  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n...                         ...  ...  ...  ...  ...  ...  ...   ...  ...  ...\n20512  ISIC_0016016_downsampled  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n20513              ISIC_0063984  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n20514              ISIC_0031341  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n20515              ISIC_0069551  0.0  0.0  0.0  0.0  0.0  0.0   0.0  1.0  0.0\n20516              ISIC_0061894  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n\n[20517 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>MEL</th>\n      <th>NV</th>\n      <th>BCC</th>\n      <th>AK</th>\n      <th>BKL</th>\n      <th>DF</th>\n      <th>VASC</th>\n      <th>SCC</th>\n      <th>UNK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0027389</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0073068</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0059070</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0072522</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0030159</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20512</th>\n      <td>ISIC_0016016_downsampled</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20513</th>\n      <td>ISIC_0063984</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20514</th>\n      <td>ISIC_0031341</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20515</th>\n      <td>ISIC_0069551</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>20516</th>\n      <td>ISIC_0061894</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20517 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_df","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.358050Z","iopub.execute_input":"2021-08-22T05:24:53.358428Z","iopub.status.idle":"2021-08-22T05:24:53.396702Z","shell.execute_reply.started":"2021-08-22T05:24:53.358390Z","shell.execute_reply":"2021-08-22T05:24:53.395485Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"             image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n0     ISIC_0033611  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n1     ISIC_0066104  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2     ISIC_0071966  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n3     ISIC_0058446  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n4     ISIC_0068391  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n...            ...  ...  ...  ...  ...  ...  ...   ...  ...  ...\n2275  ISIC_0028746  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2276  ISIC_0055141  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2277  ISIC_0072540  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n2278  ISIC_0033286  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2279  ISIC_0062754  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n\n[2280 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>MEL</th>\n      <th>NV</th>\n      <th>BCC</th>\n      <th>AK</th>\n      <th>BKL</th>\n      <th>DF</th>\n      <th>VASC</th>\n      <th>SCC</th>\n      <th>UNK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0033611</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0066104</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0071966</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0058446</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0068391</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2275</th>\n      <td>ISIC_0028746</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td>ISIC_0055141</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2277</th>\n      <td>ISIC_0072540</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2278</th>\n      <td>ISIC_0033286</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2279</th>\n      <td>ISIC_0062754</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2280 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.398148Z","iopub.execute_input":"2021-08-22T05:24:53.398583Z","iopub.status.idle":"2021-08-22T05:24:53.434229Z","shell.execute_reply.started":"2021-08-22T05:24:53.398543Z","shell.execute_reply":"2021-08-22T05:24:53.433089Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"             image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n0     ISIC_0024882  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n1     ISIC_0024380  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2     ISIC_0032639  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n3     ISIC_0073058  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n4     ISIC_0064261  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n...            ...  ...  ...  ...  ...  ...  ...   ...  ...  ...\n2529  ISIC_0065236  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2530  ISIC_0059124  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0\n2531  ISIC_0031138  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0\n2532  ISIC_0060921  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n2533  ISIC_0000289  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n\n[2534 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>MEL</th>\n      <th>NV</th>\n      <th>BCC</th>\n      <th>AK</th>\n      <th>BKL</th>\n      <th>DF</th>\n      <th>VASC</th>\n      <th>SCC</th>\n      <th>UNK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0024882</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0024380</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0032639</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0073058</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0064261</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2529</th>\n      <td>ISIC_0065236</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2530</th>\n      <td>ISIC_0059124</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2531</th>\n      <td>ISIC_0031138</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2532</th>\n      <td>ISIC_0060921</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2533</th>\n      <td>ISIC_0000289</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2534 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_ds = skin_cancer_ds(train_df, 384, \"train\")\nval_ds = skin_cancer_ds(val_df, 384, \"valid\")\ntest_ds = skin_cancer_ds(test_df, 384, \"test\")","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.435722Z","iopub.execute_input":"2021-08-22T05:24:53.436058Z","iopub.status.idle":"2021-08-22T05:24:53.445765Z","shell.execute_reply.started":"2021-08-22T05:24:53.436025Z","shell.execute_reply":"2021-08-22T05:24:53.444468Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=RandomSampler(train_ds))\nval_loader = DataLoader(val_ds, batch_size=batch_size, sampler=SequentialSampler(val_ds))\ntest_loader = DataLoader(test_ds, batch_size=batch_size, sampler=SequentialSampler(test_ds))","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.447912Z","iopub.execute_input":"2021-08-22T05:24:53.448424Z","iopub.status.idle":"2021-08-22T05:24:53.458489Z","shell.execute_reply.started":"2021-08-22T05:24:53.448385Z","shell.execute_reply":"2021-08-22T05:24:53.457029Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"DS_GCS_PATH = KaggleDatasets().get_gcs_path(\"isic-2019\")  # Trying TPU with tf.","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.460546Z","iopub.execute_input":"2021-08-22T05:24:53.460993Z","iopub.status.idle":"2021-08-22T05:24:53.889834Z","shell.execute_reply.started":"2021-08-22T05:24:53.460956Z","shell.execute_reply":"2021-08-22T05:24:53.888777Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tmp_path = \"/ISIC_2019_Training_Input/ISIC_2019_Training_Input/\"\n\ntrain_paths = [DS_GCS_PATH + tmp_path + image_name + \".jpg\" for image_name in train_df.image.values]\nval_paths = [DS_GCS_PATH + tmp_path + image_name + \".jpg\" for image_name in val_df.image.values]\ntest_paths = [DS_GCS_PATH + tmp_path + image_name + \".jpg\" for image_name in test_df.image.values]\n\ntrain_labels = train_df[CLASSES_DICT].values\nval_labels = val_df[CLASSES_DICT].values\ntest_labels = test_df[CLASSES_DICT].values","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.891083Z","iopub.execute_input":"2021-08-22T05:24:53.891582Z","iopub.status.idle":"2021-08-22T05:24:53.921742Z","shell.execute_reply.started":"2021-08-22T05:24:53.891545Z","shell.execute_reply":"2021-08-22T05:24:53.920728Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), label\n    \n    return decode_with_labels if with_labels else decode\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.9, 1.1)\n        img = tf.image.random_contrast(img, 0.9, 1.1)\n        img = tf.image.random_brightness(img, 0.1)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels=None, bsize=128, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, shuffle=1024, \n                  cache_dir=\"\"):\n    \n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    \n    slices = paths if labels is None else (paths, labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        \n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n    \n    return dset","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:24:53.923097Z","iopub.execute_input":"2021-08-22T05:24:53.923588Z","iopub.status.idle":"2021-08-22T05:24:53.944126Z","shell.execute_reply.started":"2021-08-22T05:24:53.923553Z","shell.execute_reply":"2021-08-22T05:24:53.943231Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"decoder = build_decoder(with_labels=True, target_size=(512, 512), ext='jpg')\n\ntrain_dataset = build_dataset(\n    train_paths, train_labels, bsize=batch_size, decode_fn=decoder\n)\n\nvalid_dataset = build_dataset(\n    val_paths, val_labels, bsize=batch_size, decode_fn=decoder,\n    shuffle=False, augment=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:29:29.624192Z","iopub.execute_input":"2021-08-22T05:29:29.624652Z","iopub.status.idle":"2021-08-22T05:29:30.199647Z","shell.execute_reply.started":"2021-08-22T05:29:29.624614Z","shell.execute_reply":"2021-08-22T05:29:30.198436Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = keras.Sequential([\n                keras.applications.efficientnet.EfficientNetB3(include_top=False,\n                                                               input_shape=(512, 512, 3)),\n                tf.keras.layers.GlobalAveragePooling2D(),\n                tf.keras.layers.Dense(len(CLASSES_DICT.keys()), activation='softmax')\n            ])\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(),\n                  loss='categorical_crossentropy',\n                  metrics=[tf.keras.metrics.AUC(multi_label=True)])\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'model.h5', save_best_only=True, monitor='loss', mode='min')\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor=\"loss\", patience=3, min_lr=1e-6, mode='min')\n    \nhistory = model.fit(\n    train_dataset, \n    epochs=epochs,\n    verbose=1,\n    callbacks=[checkpoint, lr_reducer])","metadata":{"execution":{"iopub.status.busy":"2021-08-22T05:57:19.558033Z","iopub.execute_input":"2021-08-22T05:57:19.558735Z","iopub.status.idle":"2021-08-22T05:57:44.376866Z","shell.execute_reply.started":"2021-08-22T05:57:19.558695Z","shell.execute_reply":"2021-08-22T05:57:44.375815Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"code","source":"efnb5_noisy_student_encoder = get_encoder(encoder_name, \n                                          in_channels=in_channels,\n                                          depth=depth,\n                                          weights=pretrained_weights)\n\nclass EfficientNetB5ClsHead(nn.Module):\n    def __init__(self, encoder, in_features):\n        super(EfficientNetB5ClsHead, self).__init__()\n        self.encoder = encoder\n        self.flatten_block = nn.Sequential(*list(self.encoder.children())[-4:])\n        \n        # Note: There seems to be a problem when I just slice the list of children layers. \n        # Deletion works however.\n        del self.encoder.global_pool\n        del self.encoder.act2\n        del self.encoder.bn2\n        del self.encoder.conv_head\n        \n        self.fc = nn.Linear(2048, in_features, bias=True)  \n        self.cls_head = nn.Linear(in_features, len(CLASSES_DICT.keys()), bias=True)\n        \n        # Xavier uniform weight initialization.\n        init.initialize_head(self.fc)\n        init.initialize_head(self.cls_head)\n    \n#     @autocast\n    def forward(self, x):\n        x = self.encoder(x)[-1]  # Output shape: (batch_size, 640, 16, 16).\n        x = self.flatten_block(x)  # Output shape: (batch_size, 2048).\n        x = self.fc(x)  # Output shape: (batch_size, 1024).\n        x = F.relu(x)  # Output shape: (batch_size, 1024).\n        x = F.dropout(x, p=0.5, training=self.training)  # Output shape: (batch_size, 1024).\n        x = self.cls_head(x)  # Output shape: (batch_size, 8).\n        return x\n    \nmodel = EfficientNetB5ClsHead(efnb5_noisy_student_encoder, in_features=in_features)","metadata":{"execution":{"iopub.status.busy":"2021-08-22T03:02:21.848457Z","iopub.execute_input":"2021-08-22T03:02:21.848789Z","iopub.status.idle":"2021-08-22T03:02:25.823805Z","shell.execute_reply.started":"2021-08-22T03:02:21.848756Z","shell.execute_reply":"2021-08-22T03:02:25.822985Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b5_ns-6f26d0cf.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_b5_ns-6f26d0cf.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8af0e3f71594a598bbfcf326680872b"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model.to(device)\n\n# To handle class imbalance we can weigh each class. \n# Do something like this and pass it into the Loss function:\n\n# CE_weights = torch.zeros(len(CLASSES_DICT.keys()))  # This takes into account the imbalanced dataset.\n# Increment CE_weights e.g. class 0 has 2439 counts then CE_weights[0] has 2439.\n# CE_weights = 1. / CEweights.clamp_(min=1.)  # Weights should be inversely related to count.\n# CE_weights = (CE_weights * numClass / CE_weights.sum()).to(device)\n\ncriterion = nn.CrossEntropyLoss(weight=None)\noptimizer = torch.optim.Adam(model.parameters(), lr=init_lr)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs-1)\nscaler = torch.cuda.amp.GradScaler()\n\nval_loss_min = np.Inf  # Save model with best performance on val_loss.\n\nrun = wandb.init(project=\"cancer_classification_IH2021\", name=f\"efnb5-noisy-stdnt\")  # Initialize a project.\n\nfor epoch in range(1, epochs+1):\n    scheduler.step()\n    model.train()\n    train_loss = []\n\n    loop = tqdm(train_loader)\n    for images, labels in loop:\n        images = images.to(device)\n        labels = labels.to(device)\n                \n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast(): \n            outputs = model(images)\n            loss = criterion(outputs.float(), labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        train_loss.append(loss.item())\n        loop.set_description('Epoch {:02d}/{:02d}'.format(epoch, epochs))\n        loop.set_postfix(loss=np.mean(train_loss))\n        \n        del images, labels\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n    train_loss = np.mean(train_loss)\n\n    model.eval()\n\n    val_loss = 0.0\n    for images, labels in tqdm(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        with torch.cuda.amp.autocast(), torch.no_grad():\n            outputs = model(images)\n            loss = criterion(outputs.float(), labels)\n                \n        val_loss += loss.item() * images.size(0)\n            \n        del images, labels\n        gc.collect()\n        torch.cuda.empty_cache()\n            \n    val_loss = val_loss / len(valid_loader.dataset)\n            \n    print('train loss: {:.5f} | val_loss: {:.5f}'.format(train_loss, val_loss))\n            \n    wandb.log({\"epoch\": epoch, \n            \"loss\": train_loss, \n            \"val_loss\": val_loss,\n        })\n            \n    if val_loss < val_loss_min:\n        print('Valid loss improved from {:.5f} to {:.5f}, saving model to wandb.'.format(val_loss_min, val_loss))\n        val_loss_min = val_loss\n        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n        artifact = wandb.Artifact(encoder_name, type='model')\n        artifact.add_file(MODEL_SAVE_PATH, name=f\"model{epoch}.pt\")\n        run.log_artifact(artifact)\n        \n    del train_loss\n    gc.collect()\n    torch.cuda.empty_cache()\n        \nrun.finish()","metadata":{"execution":{"iopub.status.busy":"2021-08-22T03:02:31.570838Z","iopub.execute_input":"2021-08-22T03:02:31.571196Z","iopub.status.idle":"2021-08-22T03:03:19.969425Z","shell.execute_reply.started":"2021-08-22T03:02:31.571164Z","shell.execute_reply":"2021-08-22T03:03:19.967470Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m (use `wandb login --relogin` to force relogin)\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.0 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.33<br/>\n                Syncing run <strong style=\"color:#cdcd00\">efnb7-noisy-stdnt</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/vincenttu/cancer_classification_IH2021\" target=\"_blank\">https://wandb.ai/vincenttu/cancer_classification_IH2021</a><br/>\n                Run page: <a href=\"https://wandb.ai/vincenttu/cancer_classification_IH2021/runs/2n1pgr5o\" target=\"_blank\">https://wandb.ai/vincenttu/cancer_classification_IH2021/runs/2n1pgr5o</a><br/>\n                Run data is saved locally in <code>/kaggle/working/wandb/run-20210822_030236-2n1pgr5o</code><br/><br/>\n            "},"metadata":{}},{"name":"stderr","text":"Epoch 01/20:   1%|          | 9/1026 [00:36<1:07:57,  4.01s/it, loss=2.06]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e3a5142e608f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}